---
layout: post
title: Sustainability et GenAI
image:
  path: /assets/img/blog/Sustainability.jpg
description: >
  Start calculating the CO2 emissions of your GenAI models
sitemap: false
---

Measuring the environmental impact of digital: Why estimate carbon emissions (quantity of CO₂e emissions)?

- Refine practices by using figures to determine whether an investment in a project is justified.
- Provide figures to CSR departments responsible for producing an annual CSR report.
- Objectively assess the impact of IT to facilitate dialogue on the subject.
  Or simply because, as Niels Bohr put it, “Nothing exists until it is measured”.

These reasons are relevant to every digital project. Assessing CO2 emissions for GENAI projects raises questions such as: how much CO2 equivalent did a generative model consume to be used? What is the environmental cost of sending an e-mail generated by a GenAI model? How can the carbon footprint of models be reduced?

$${\color{green}The \space main \space recommendation \space is \space to \space start \space by \space estimating \space the \space carbon \space footprint \space of \space AI \space generative \space models}$$

There are no tools for estimating the total carbon footprint of the AI field. But the carbon footprint of a machine learning model can be estimated by the electricity consumption of the training procedure or inference. All software, from phone apps to cloud-based data science pipelines, consumes electricity. As not all electricity is generated from renewable sources, this consumption contributes to a carbon footprint.

Thanks to the Electricity Map tool [Link to the tool], it's possible to take action on the carbon footprint of codes. Electricity Maps is a 24/7 live visualization of where electricity comes from and how much CO2 is emitted to produce it. As a result, there's enough information to determine in which country it's best to locate servers.

Electricity production in France has very low CO2 emissions, largely thanks to its nuclear fleet and the development of renewable energies.

The carbon footprint of a machine learning model can be estimated by estimating the electricity consumption of the training procedure or inference. To obtain a carbon footprint estimate with this tool, simply enter the following parameters: Hardware type (GPU, CPU...), Number of hours the hardware was used, Cloud provider used, and Cloud region where the calculation took place (for example, “europe-north1”).

The measurement of a server's power consumption is the sum of the power consumption of all its components. The first component is the measurement of CPU power consumption, performed by the RAPL interface on Unix operating systems or by Intel Power Gadget on Mac and Windows. The RAPL interface also provides RAM power consumption. The third component is the measurement of GPU power consumption, obtained via Nvidia SMI, which provides real-time power consumption via its interface or via Python (pyNVML).

$${\color{green}CodeCarbon: \space the \space essential \space tool \space for \space assessing \space the \space environmental \space impact \space of \space generative \space AI \space models}$$

There's a tool that lets you make the estimate directly by integrating it into the code. CodeCarbon is an open-source Python package designed to estimate the carbon footprint of machine learning models and other applications. It takes into account hardware energy consumption, including GPU, CPU and RAM, as well as the carbon intensity of the computational region at fixed intervals, e.g. every 15 seconds. By monitoring energy consumption and multiplying by carbon intensity, CodeCarbon provides an estimate of the carbon dioxide equivalents (CO2e) used in a single run.

Integrating CodeCarbon with the inference code is relatively straightforward, as this script demonstrates:
<code style="color : Green">
tracker = EmissionsTracker()  
tracker.start()

#code de l’inférence API pour appeler le modèle  
#pour effectuer un l'inférence

model.predict(data)  
emissions: float = tracker.stop()
</code>

CodeCarbon has a built-in log that records data in a CSV file named emissions.csv in the output directory, for each experiment tracked across projects. The most important features are emissions (emissions in CO₂ equivalents [CO₂eq], in kg), emissions_rate (emissions divided by time, in kg/s), cpu_power (processor power (W)), gpu_power (GPU power (W)), ram_power (RAM power (W)), energy_consumed (sum of cpu_energy, gpu_energy and ram_energy (kWh)), Country_name (name of the country where the infrastructure is hosted), etc.

CodeCarbon also comes with carbonboard, which provides a dashboard for data visualization. Users can understand the net energy consumption and emissions generated across projects, and can immerse themselves in a particular experiment or project.

<img src="/assets/img/blog/footprintcarbon.png" alt="drawing" width="800"/>

For an example of the Llama2 generative model, the model emitted an average of 0.0002kg of CO2 with the GPU environment. By repeating the experiment 100 times to make more inferences with the same model, 0.1kg of carbon equivalent were emitted (equivalent to 31 minutes of TV or 0.03% of weekly US household emissions). To put this into perspective, 1 h of visio, for two, with the camera emits 66 g CO2e on average in France. So much for the figures! Now it's up to you to imagine the impact of our future Generative Models on our carbon footprint. Who would have thought that our discussions could carry such weight?

[Link to the tool]: https://app.electricitymaps.com/map
